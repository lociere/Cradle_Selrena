"""
éŸ³é¢‘æµå¤„ç†ï¼ˆAudio Streamï¼‰

èŒè´£ï¼š
- æ•è·éŸ³é¢‘æµå¹¶è¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰ã€‚
"""

import asyncio
import numpy as np
import sounddevice as sd
import webrtcvad
import time
from typing import Optional
from cradle.selrena.synapse.event_bus import global_event_bus
from cradle.schemas.protocol.events.base import BaseEvent
from cradle.utils.logger import logger

from cradle.core.config_manager import global_config
from cradle.selrena.vessel.perception.audio.asr_client import FunASRClient
from cradle.utils.path import ProjectPath

class AudioStream:
    """
    éŸ³é¢‘æµæ•è·ä¸VAD(è¯­éŸ³æ´»åŠ¨æ£€æµ‹)
    ä½¿ç”¨ sounddevice è¯»å–éº¦å…‹é£ï¼Œwebrtcvad æ£€æµ‹è¯­éŸ³ï¼Œåˆ†æ®µé€å…¥ ASR
    """
    def __init__(self):
        self.logger = logger
        # æš‚æ—¶æ‰‹åŠ¨è·å– loopï¼Œå› ä¸º __init__ å¯èƒ½ä¸åœ¨ loop è¿è¡Œçš„çº¿ç¨‹
        try:
            self.loop = asyncio.get_running_loop()
        except RuntimeError:
            self.loop = None
            
        self.config = global_config.get_system().perception.audio
        self.asr_client = FunASRClient()
        
        # Debug ç›®å½•
        self.debug_dir = ProjectPath.LOGS_DIR / "debug_audio"
        self.debug_dir.mkdir(exist_ok=True)


        
        # VAD è®¾ç½®
        # é™çº§ VAD çµæ•åº¦å·²é¿å…åˆ‡æ‰é¦–éŸ³èŠ‚ (3 -> 2)
        self.vad = webrtcvad.Vad(2) # 0-3, 3 is most aggressive
        self.sample_rate = 16000 # webrtcvad supports 8k, 16k, 32k, 48k
        self.frame_duration_ms = 30 # 10, 20, or 30ms
        self.frame_size = int(self.sample_rate * self.frame_duration_ms / 1000)
        
        # çŠ¶æ€
        self.is_listening = False
        self.buffer = bytearray()
        self.speech_buffer = bytearray()
        self.is_speech_active = False
        self.silence_frames_count = 0
        self.max_silence_frames = 20 # çº¦ 600ms é™éŸ³åˆ¤å®šç»“æŸ
        
        # 4. å”¤é†’ä¸äº¤äº’çŠ¶æ€ç®¡ç†
        self.last_wake_time = 0
        self.wake_timeout = 30.0  # å”¤é†’åç»´æŒ 30ç§’ æ´»è·ƒçŠ¶æ€
        
        # å”¤é†’è¯ä¸é€€å‡ºæŒ‡ä»¤ - å·²ç§»äº¤ synapse å±‚å¤„ç†
        # ...existing code...
        
    def _ensure_loop(self):
         if not self.loop:
             try:
                 self.loop = asyncio.get_running_loop()
             except RuntimeError:
                 self.logger.error("AudioStream needs a running asyncio loop.")

    def _audio_callback(self, indata, frames, time_info, status):
        """SoundDevice å›è°ƒ (åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ)"""
        if status:
            pass # print(status)
            
        # indata is float32 by default, convert to int16 for webrtcvad
        audio_data = (indata * 32767).astype(np.int16)
        
        # å•å£°é“å¤„ç† (indata might be [frames, channels])
        if audio_data.ndim > 1:
            audio_data = audio_data[:, 0]
            
        raw_bytes = audio_data.tobytes()
        
        try:
            is_speech = self.vad.is_speech(raw_bytes, self.sample_rate)
        except Exception:
            is_speech = False

        if is_speech:
            if not self.is_speech_active:
                # self.logger.debug("Detected speech start")
                self.is_speech_active = True
            
            self.silence_frames_count = 0
            self.speech_buffer.extend(raw_bytes)
        else:
            if self.is_speech_active:
                self.silence_frames_count += 1
                self.speech_buffer.extend(raw_bytes) 
                
                if self.silence_frames_count > self.max_silence_frames:
                    # è¯­éŸ³ç»“æŸ
                    self.is_speech_active = False
                    self._process_speech(self.speech_buffer[:])
                    self.speech_buffer.clear()
                    self.silence_frames_count = 0

    def _process_speech(self, audio_bytes):
        """å°†éŸ³é¢‘ç‰‡æ®µæäº¤ç»™ ASR"""
        # 1. è¿‡æ»¤è¿‡çŸ­çš„éŸ³é¢‘ (å°äº 0.3ç§’ å¯èƒ½æ˜¯æ‚éŸ³)
        # 16k * 2bytes * 0.3s = 9600 bytes
        if len(audio_bytes) < 9600:
             return

        # 2. èƒ½é‡æ£€æµ‹ (RMS) - è¿‡æ»¤æ‰è™½ç„¶è§¦å‘VADä½†éŸ³é‡æä½çš„åº•å™ª
        audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
        rms = np.sqrt(np.mean(audio_int16.astype(np.float64)**2))
        
        # è°ƒè¯•è¾“å‡ºèƒ½é‡å€¼
        # self.logger.info(f"ğŸ¤ Speech Segment Detected | RMS: {rms:.2f} | Length: {len(audio_bytes)/32000:.2f}s")
        
        # é˜ˆå€¼ç»éªŒå€¼: 500 (éå¸¸å®‰é™) - 3000 (æ­£å¸¸è¯´è¯)
        # å¦‚æœ RMS å°äº 800ï¼Œé€šå¸¸åªæ˜¯ç¯å¢ƒåº•å™ª
        if rms < 800:
             return

        # ç¡®ä¿æœ‰ loop å¼•ç”¨
        if not self.loop:
             return

        # è½¬æ¢ä¸º Float32 ä¾› ASR ä½¿ç”¨ (SenseVoice éœ€è¦ float32)
        audio_float32 = audio_int16.astype(np.float32) / 32768.0
        
        # 3. æ™ºèƒ½å½’ä¸€åŒ– (Smart Normalization)
        # åªæœ‰å½“éŸ³é‡ç¡®å®åå°(ä½†ä¸æ˜¯çº¯å™ª)æ—¶æ‰æ”¾å¤§ï¼Œä¸”é™åˆ¶æ”¾å¤§å€æ•°ï¼Œé¿å…æŠŠåº•å™ªç‚¸æˆå·¨å“
        max_val = np.max(np.abs(audio_float32))
        
        # ä¸¥æ ¼æ§åˆ¶æ”¾å¤§é€»è¾‘ï¼š
        # å¦‚æœ max_val å°äº 0.1 (æå¼±ä¿¡å·)ï¼Œè¿™é€šå¸¸å°±æ˜¯çº¯åº•å™ªï¼Œæ ¹æœ¬ä¸è¦æ”¾å¤§ï¼Œä¿æŒåŸæ ·ç”šè‡³å¯ä»¥è¡°å‡
        if max_val < 0.1:
            pass # Do nothing
        elif max_val < 0.5:
             # çº¿æ€§æ”¾å¤§åˆ° 0.7 å·¦å³ï¼Œä½†å€æ•°ä¸è¶…è¿‡ 2
             scale_factor = 0.7 / max_val
             scale_factor = min(scale_factor, 2.0)
             audio_float32 = audio_float32 * scale_factor
        else:
             # ä¿¡å·è¶³å¤Ÿå¼ºï¼Œåªåšè½»å¾®è¡°å‡é˜²æ­¢å‰Šæ³¢
             audio_float32 = audio_float32 / max_val * 0.95
        
        # ...existing code...

        asyncio.run_coroutine_threadsafe(
            self._transcribe_and_publish(audio_float32), 
            self.loop
        )

    async def _transcribe_and_publish(self, audio_data):
        """å¼‚æ­¥æ‰§è¡Œ ASR å¹¶å‘å¸ƒäº‹ä»¶"""
        if not self.asr_client:
            return

        try:
             # è¿è¡Œ ASR (åˆ‡æ¢å› zh æ¨¡å¼ï¼Œå¯¹äºä¸­æ–‡å¯¹è¯æ›´ç¨³å®šï¼Œé…åˆä¸‹æ–¹çš„è¿‡æ»¤å™¨)
            text = await asyncio.to_thread(self.asr_client.transcribe, audio_data, language="zh")
        
            if not text or len(text.strip()) == 0:
                return

            # å½’ä¸€åŒ–æ–‡æœ¬ä»¥ä¾¿åŒ¹é… (å»æ ‡ç‚¹ã€è½¬å°å†™)
            import re
            # ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ï¼Œå»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·
            text_clean = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text).lower()

            # é€»è¾‘ç§»äº¤: åŸå§‹æ–‡æœ¬ç›´æ¥ä¸ŠæŠ¥ç»™ Synapse å±‚ (Reflex & Cortex)
            self.logger.debug(f"ğŸ‘‚ Transcribed: {text_clean}")
        
            await global_event_bus.publish(BaseEvent(
                name="perception.audio.transcription",
                payload={"text": text, "clean_text": text_clean},
                source="Ear"
            ))
        except Exception as e:
            self.logger.error(f"ASR Task Failed: {e}")

    async def listen_loop(self):
        """å¯åŠ¨ç›‘å¬ (æ›¿ä»£æ—§çš„æ–¹æ³•å)"""
        self.loop = asyncio.get_running_loop()
        await self.start()

    async def start(self):
        """å¯åŠ¨ç›‘å¬"""
        if self.is_listening:
            return
            
        device_index = self.config.device_index
        
        try:
            self.stream = sd.InputStream(
                samplerate=self.sample_rate,
                blocksize=self.frame_size,
                device=device_index,
                channels=1,
                dtype="float32",
                callback=self._audio_callback
            )
            self.stream.start()
            self.is_listening = True
            self.logger.info(f"Microphone listening started (Device: {device_index if device_index is not None else 'Default'}).")
            
            # ä¿æŒåç¨‹è¿è¡Œï¼Œç›´åˆ°åœæ­¢
            try:
                while self.is_listening:
                    await asyncio.sleep(1)
            except asyncio.CancelledError:
                self.stop()
                
        except Exception as e:
            self.logger.critical(f"Failed to start microphone stream: {e}")

    def stop(self):
        """åœæ­¢ SoundDevice æµ"""
        if hasattr(self, 'stream') and self.stream:
            if not self.stream.closed:
                self.stream.stop()
                self.stream.close()
            self.stream = None # é¿å…é‡å¤å…³é—­
            
        self.is_listening = False
        self.logger.info("Microphone listening stopped.")

    async def cleanup(self):
        """ç”Ÿå‘½å‘¨æœŸé’©å­: å®‰å…¨é‡Šæ”¾éŸ³é¢‘èµ„æº"""
        self.stop()
        self.logger.info("Audio system cleaned up.")

# å…¼å®¹æ—§ä»£ç æ¥å£ - åŸ SemanticEar
SemanticEar = AudioStream
