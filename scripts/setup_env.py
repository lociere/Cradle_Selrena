import sys
import subprocess
import platform
import os
import argparse
import shutil

# ================= Configuration =================
# æ ¸å¿ƒä¾èµ– (Core): ç³»ç»Ÿè¿è¡Œçš„åŸºç¡€ï¼Œå¿…é¡»å®‰è£…
CORE_REQUIREMENTS = [
    "pydantic>=2.0",
    "python-dotenv",
    "pyyaml",
    "loguru",
    "numpy",
    "requests",
    "pillow",
    "pyautogui",  # è§†è§‰æ„ŸçŸ¥/æ“ä½œ
]

# AI å¼•æ“ (Intelligence): æ¶‰åŠ PyTorch, ModelScope, LLM
# æ³¨æ„ï¼štorch å’Œ llama-cpp-python ä¼šåœ¨è„šæœ¬ä¸­ç‰¹æ®Šå¤„ç†
AI_REQUIREMENTS = [
    "openai>=1.0",
    "langchain",
    "langgraph",
    "modelscope",
    "funasr",          # è¯­éŸ³è¯†åˆ«
    "sounddevice",     # éŸ³é¢‘è¾“å…¥è¾“å‡º
    # "soundfile",  # å·²ç§»é™¤
    "scipy",
    "chromadb",             # å‘é‡æ•°æ®åº“ (Project Mnemosyne)
    "sentence-transformers" # CPU Embedding (Project Mnemosyne)
]

# ç”¨æˆ·ç•Œé¢ (GUI): å¯é€‰
GUI_REQUIREMENTS = [
    "PySide6",
]

# å¼€å‘å·¥å…· (Dev): å¯é€‰ï¼Œç”¨äºæ ¼å¼åŒ–ã€æµ‹è¯•ç­‰
DEV_REQUIREMENTS = [
    "black",
    "pytest",
    "huggingface_hub", # ç”¨äºå¤‡ç”¨ä¸‹è½½
]

# é•œåƒæº (Mirror)
PIP_INDEX_URL = "https://pypi.tuna.tsinghua.edu.cn/simple"

# ================= Helpers =================

def run_pip(args, description):
    """è¿è¡Œ pip å‘½ä»¤"""
    print(f"ğŸ“¦ [Setup] {description}...")
    cmd = [sys.executable, "-m", "pip", "install", "-i", PIP_INDEX_URL] + args
    try:
        subprocess.check_call(cmd)
        print(f"âœ… {description} å®Œæˆ.\n")
    except subprocess.CalledProcessError:
        print(f"âŒ {description} å¤±è´¥!")
        # æ ¸å¿ƒç»„ä»¶å¤±è´¥ç›´æ¥é€€å‡º
        if "llama-cpp-python" in str(args) or "torch" in str(args):
            print("   è¿™æ˜¯ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œå®‰è£…æ— æ³•ç»§ç»­ã€‚")
            sys.exit(1)

def check_nvidia_gpu():
    """ç®€å•çš„ NVIDIA GPU æ£€æµ‹"""
    try:
        # æ–¹æ³•1: å°è¯•è°ƒç”¨ nvidia-smi
        subprocess.check_output("nvidia-smi")
        print("âœ… æ£€æµ‹åˆ° NVIDIA GPU (é€šè¿‡ nvidia-smi)")
        return True
    except:
        pass
    
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šæ£€æµ‹é€»è¾‘
    print("âš ï¸ æœªæ£€æµ‹åˆ° nvidia-smiï¼Œå°†å‡å®šæ—  NVIDIA GPUï¼ˆæˆ–é©±åŠ¨æœªé…ç½®ï¼‰ã€‚")
    return False

def check_cuda_compiler():
    """æ£€æµ‹ nvcc"""
    try:
        subprocess.check_output(["nvcc", "--version"])
        print("âœ… æ£€æµ‹åˆ° CUDA Compiler (nvcc)")
        return True
    except:
        print("âš ï¸ æœªæ£€æµ‹åˆ° nvccã€‚å¦‚æœè¿™æ˜¯ä¸€ä¸ª NVIDIA ç¯å¢ƒï¼Œå»ºè®®å®‰è£… CUDA Toolkit ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚")
        return False

# ================= Main Tasks =================

def install_torch(has_gpu):
    """å®‰è£… PyTorch"""
    if has_gpu:
        print("ğŸš€ æ­£åœ¨ä¸ºæ‚¨å®‰è£… GPU ç‰ˆ PyTorch (CUDA 12.4)...")
        # ç›´æ¥æŒ‡å®š pytorch.org çš„ index å¯èƒ½æ¯”è¾ƒæ…¢ï¼Œä½†å®ƒæ˜¯æœ€ç¨³çš„
        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ pip çš„ --extra-index-url é…åˆæ¸…åæº
        # é’ˆå¯¹ CUDA 12.4
        run_pip(
            ["torch", "torchvision", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cu124"],
            "å®‰è£… PyTorch (CUDA 12.4)"
        )
    else:
        print("ğŸ¢ æ­£åœ¨ä¸ºæ‚¨å®‰è£… CPU ç‰ˆ PyTorch...")
        run_pip(["torch", "torchvision", "torchaudio"], "å®‰è£… PyTorch (CPU)")

def install_llama_cpp(has_gpu, cuda_version="cu124"):
    """å®‰è£… llama-cpp-python"""
    pkg_name = "llama-cpp-python"
    
    # å…ˆå°è¯•å¸è½½ï¼Œé¿å…ç‰ˆæœ¬å†²çª
    subprocess.call([sys.executable, "-m", "pip", "uninstall", "-y", pkg_name])

    if has_gpu:
        # å¿…é¡»æ£€æŸ¥ nvccï¼Œå¦åˆ™ gpu ç¼–è¯‘ä¼šå¤±è´¥ï¼Œæˆ–è€…ä½¿ç”¨é¢„ç¼–è¯‘ wheels
        print(f"ğŸš€ æ­£åœ¨å®‰è£… {pkg_name} (GPU/CUDA)...")
        
        # ä½¿ç”¨ abetlen çš„é¢„ç¼–è¯‘è½®å­ï¼Œè¿™æ˜¯æœ€ç¨³å¥çš„æ–¹æ³•ï¼Œé¿å…æœ¬åœ°ç¼–è¯‘ç¯å¢ƒé—®é¢˜
        wheel_url = f"https://abetlen.github.io/llama-cpp-python/whl/{cuda_version}"
        
        # å¼ºåˆ¶é‡æ–°å®‰è£…ï¼Œä¸å®‰è£…ä¾èµ–ï¼ˆä¾èµ–ç”±æˆ‘ä»¬è‡ªå·±æ§åˆ¶ï¼‰
        cmd = [
            sys.executable, "-m", "pip", "install", pkg_name,
            "--force-reinstall",
            "--no-deps",
            "--extra-index-url", wheel_url
        ]
        print(f"   Command: {' '.join(cmd)}")
        try:
            subprocess.check_call(cmd)
            print(f"âœ… {pkg_name} (GPU) å®‰è£…å®Œæˆ.\n")
        except subprocess.CalledProcessError:
            print(f"âŒ {pkg_name} (GPU) å®‰è£…å¤±è´¥ã€‚å°è¯•å›é€€åˆ°æºç ç¼–è¯‘æ¨¡å¼...")
            # å›é€€ç­–ç•¥ï¼šè®¾ç½® CMAKE å‚æ•°ä»æºç å®‰è£…
            env = os.environ.copy()
            env["CMAKE_ARGS"] = "-DGGML_CUDA=on"
            subprocess.check_call(
                [sys.executable, "-m", "pip", "install", pkg_name, "-i", PIP_INDEX_URL],
                env=env
            )
    else:
        print(f"ğŸ¢ æ­£åœ¨å®‰è£… {pkg_name} (CPU Mode)...")
        run_pip([pkg_name], f"å®‰è£… {pkg_name}")

def main():
    parser = argparse.ArgumentParser(description="Cradle Selrena ç¯å¢ƒéƒ¨ç½²è„šæœ¬")
    
    # é€‰é¡¹å¼€å…³
    parser.add_argument("--cpu", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨ CPU æ¨¡å¼ (ä¸å®‰è£… CUDA ç›¸å…³åº“)")
    parser.add_argument("--no-gui", action="store_true", help="è·³è¿‡ GUI åº“ (PySide6) å®‰è£…")
    parser.add_argument("--dev", action="store_true", help="å®‰è£…å¼€å‘å·¥å…· (pytest, black, etc.)")
    parser.add_argument("--upgrade", action="store_true", help="å‡çº§æ‰€æœ‰åŒ…")
    
    args = parser.parse_args()

    print("==================================================")
    print(" ğŸ› ï¸  Cradle Selrena ç¯å¢ƒéƒ¨ç½²å‘å¯¼")
    print("==================================================")
    print(f"Python: {sys.version.split()[0]}")
    print(f"Platform: {platform.system()} {platform.release()}")
    
    # 1. ç¡¬ä»¶æ£€æµ‹
    has_nvidia = False
    if not args.cpu:
        has_nvidia = check_nvidia_gpu()
        if has_nvidia:
            check_cuda_compiler() # åªæ˜¯ç»™ä¸ªæç¤º
    else:
        print("âš ï¸ ç”¨æˆ·å¼ºåˆ¶æŒ‡å®š --cpuï¼Œè·³è¿‡ GPU æ£€æµ‹ã€‚")

    # 2. å‡çº§ pip
    subprocess.call([sys.executable, "-m", "pip", "install", "--upgrade", "pip", "-i", PIP_INDEX_URL])

    # 3. å®‰è£… PyTorch
    install_torch(has_nvidia)

    # 4. å®‰è£… llama-cpp-python (æœ€å…³é”®çš„ LLM å¼•æ“)
    # åªæœ‰åœ¨ Windows + Nvidia ç¯å¢ƒä¸‹ï¼Œæˆ‘ä»¬é»˜è®¤ä½¿ç”¨ cu124 è½®å­
    # å…¶ä»–ç¯å¢ƒå¯èƒ½éœ€è¦è°ƒæ•´é€»è¾‘ï¼Œè¿™é‡Œé’ˆå¯¹æ‚¨çš„ Windows ç¯å¢ƒä¼˜åŒ–
    install_llama_cpp(has_nvidia, cuda_version="cu124")

    # 5. å®‰è£…æ ¸å¿ƒä¾èµ–
    run_pip(CORE_REQUIREMENTS, "å®‰è£…æ ¸å¿ƒä¾èµ– (Core)")

    # 6. å®‰è£… AI ä¾èµ–
    run_pip(AI_REQUIREMENTS, "å®‰è£… AI/è¯­éŸ³ç»„ä»¶")

    # 7. å¯é€‰ç»„ä»¶
    if not args.no_gui:
        run_pip(GUI_REQUIREMENTS, "å®‰è£… GUI ç»„ä»¶ (PySide6)")
    else:
        print("â­ï¸  è·³è¿‡ GUI ç»„ä»¶ã€‚")

    if args.dev:
        run_pip(DEV_REQUIREMENTS, "å®‰è£…å¼€å‘å·¥å…·")
    
    print("==================================================")
    print(" ğŸ‰ ç¯å¢ƒéƒ¨ç½²å®Œæˆï¼")
    print("==================================================")
    print("ä¸‹ä¸€æ­¥å»ºè®®ï¼š")
    print("1. è¿è¡Œä¸‹è½½è„šæœ¬: python scripts/download_model.py")
    print("2. å¯åŠ¨ç³»ç»Ÿ:     python src/cradle/main.py")

if __name__ == "__main__":
    main()
